---
title: "Multi-Modal AI ê¸°ì´ˆ"
author: iwindfree
pubDatetime: 2025-01-22T09:00:00Z
slug: "llm-multimodal-basic"
category: "LLM Engineering"
series: "LLM Engineering"
seriesOrder: 9
tags: ["ai", "llm", "multimodal"]
description: "Multi-Modal AIëŠ” í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ìŒì„± ë“± ì—¬ëŸ¬ í˜•íƒœì˜ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” AIì…ë‹ˆë‹¤."
---

Multi-Modal AIëŠ” **í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ìŒì„±** ë“± ì—¬ëŸ¬ í˜•íƒœì˜ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” AIì…ë‹ˆë‹¤.

## Multi-Modalì´ë€?

ê¸°ì¡´ LLMì€ í…ìŠ¤íŠ¸ë§Œ ì…ì¶œë ¥í–ˆì§€ë§Œ, Multi-Modal AIëŠ” ë‹¤ì–‘í•œ í˜•íƒœì˜ ë°ì´í„°ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤.

| ê¸°ëŠ¥ | ì…ë ¥ | ì¶œë ¥ | API/ëª¨ë¸ |
|------|------|------|----------|
| í…ìŠ¤íŠ¸ ìƒì„± | í…ìŠ¤íŠ¸ | í…ìŠ¤íŠ¸ | GPT-4o |
| ì´ë¯¸ì§€ ë¶„ì„ (Vision) | ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ | í…ìŠ¤íŠ¸ | GPT-4o |
| ì´ë¯¸ì§€ ìƒì„± | í…ìŠ¤íŠ¸ | ì´ë¯¸ì§€ | DALL-E 3 |
| ìŒì„± ìƒì„± (TTS) | í…ìŠ¤íŠ¸ | ìŒì„± | TTS API |
| ìŒì„± ì¸ì‹ (STT) | ìŒì„± | í…ìŠ¤íŠ¸ | Whisper |

### í™œìš© ì‚¬ë¡€

- **ê³ ê° ì„œë¹„ìŠ¤**: ìŒì„±ìœ¼ë¡œ ì§ˆë¬¸í•˜ê³  ìŒì„±ìœ¼ë¡œ ë‹µë³€ ë°›ê¸°
- **ì½˜í…ì¸  ìƒì„±**: ë¸”ë¡œê·¸ ê¸€ì— ë§ëŠ” ì´ë¯¸ì§€ ìë™ ìƒì„±
- **ì ‘ê·¼ì„±**: ì‹œê° ì¥ì• ì¸ì„ ìœ„í•œ ì´ë¯¸ì§€ ì„¤ëª…
- **êµìœ¡**: ê°œë… ì„¤ëª…ê³¼ í•¨ê»˜ ì‹œê° ìë£Œ ìƒì„±


```python
import base64
from io import BytesIO
from pathlib import Path

from openai import OpenAI
from PIL import Image
from IPython.display import Audio, display

client = OpenAI()
```


---

## 1. ì´ë¯¸ì§€ ìƒì„± (DALL-E 3)

í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¡œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

### API íŒŒë¼ë¯¸í„°

| íŒŒë¼ë¯¸í„° | ì„¤ëª… | ì˜µì…˜ |
|----------|------|------|
| `model` | ì‚¬ìš©í•  ëª¨ë¸ | `dall-e-3`, `dall-e-2` |
| `prompt` | ì´ë¯¸ì§€ ì„¤ëª… | í…ìŠ¤íŠ¸ |
| `size` | ì´ë¯¸ì§€ í¬ê¸° | `1024x1024`, `1792x1024`, `1024x1792` |
| `quality` | í’ˆì§ˆ | `standard`, `hd` |
| `response_format` | ì‘ë‹µ í˜•ì‹ | `url`, `b64_json` |

> **ë¹„ìš© ì°¸ê³ **: DALL-E 3 1024x1024 ì´ë¯¸ì§€ 1ì¥ë‹¹ ì•½ $0.04 (ì•½ 50ì›)


```python
def generate_image(prompt: str, size: str = "1024x1024") -> Image.Image:
    """DALL-E 3ë¡œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    response = client.images.generate(
        model="dall-e-3",
        prompt=prompt,
        size=size,
        n=1,
        response_format="b64_json"
    )
    
    # Base64 ë””ì½”ë”© â†’ PIL Image
    image_base64 = response.data[0].b64_json
    image_data = base64.b64decode(image_base64)
    return Image.open(BytesIO(image_data))
```



```python
# ì´ë¯¸ì§€ ìƒì„± í…ŒìŠ¤íŠ¸
image = generate_image(
    "A cozy coffee shop interior with warm lighting, "
    "wooden furniture, and a cat sleeping on a cushion, "
    "digital art style"
)
display(image)
```



![output](/images/notebooks/llm-multimodal-basic-img-1.png)


---

## 2. ìŒì„± ìƒì„± (Text-to-Speech)

í…ìŠ¤íŠ¸ë¥¼ ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

### API íŒŒë¼ë¯¸í„°

| íŒŒë¼ë¯¸í„° | ì„¤ëª… | ì˜µì…˜ |
|----------|------|------|
| `model` | TTS ëª¨ë¸ | `tts-1`, `tts-1-hd`, `gpt-4o-mini-tts` |
| `voice` | ìŒì„± ìŠ¤íƒ€ì¼ | `alloy`, `echo`, `fable`, `onyx`, `nova`, `shimmer` |
| `input` | ë³€í™˜í•  í…ìŠ¤íŠ¸ | ìµœëŒ€ 4096ì |

### ìŒì„± ìŠ¤íƒ€ì¼ íŠ¹ì§•

| Voice | íŠ¹ì§• |
|-------|------|
| `alloy` | ì¤‘ì„±ì , ê· í˜• ì¡íŒ í†¤ |
| `echo` | ë”°ëœ»í•˜ê³  ë¶€ë“œëŸ¬ìš´ ë‚¨ì„± ìŒì„± |
| `fable` | í‘œí˜„ë ¥ ìˆëŠ” ì˜êµ­ì‹ ì–µì–‘ |
| `onyx` | ê¹Šê³  ê¶Œìœ„ ìˆëŠ” ë‚¨ì„± ìŒì„± |
| `nova` | ì¹œê·¼í•˜ê³  ì—ë„ˆì§€ ë„˜ì¹˜ëŠ” ì—¬ì„± ìŒì„± |
| `shimmer` | ëª…í™•í•˜ê³  ì „ë¬¸ì ì¸ ì—¬ì„± ìŒì„± |


```python
def text_to_speech(text: str, voice: str = "nova") -> bytes:
    """í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    response = client.audio.speech.create(
        model="tts-1",
        voice=voice,
        input=text
    )
    return response.content
```



```python
# TTS í…ŒìŠ¤íŠ¸
audio_data = text_to_speech(
    "ì•ˆë…•í•˜ì„¸ìš”! Multi-Modal AIì˜ ì„¸ê³„ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤. "
    "ì´ì œ AIê°€ í…ìŠ¤íŠ¸ë¿ë§Œ ì•„ë‹ˆë¼ ì´ë¯¸ì§€ì™€ ìŒì„±ë„ ë‹¤ë£° ìˆ˜ ìˆìŠµë‹ˆë‹¤."
)

# ë…¸íŠ¸ë¶ì—ì„œ ì˜¤ë””ì˜¤ ì¬ìƒ
Audio(audio_data, autoplay=True)
```



<div class="nb-output">

```text
<IPython.lib.display.Audio object>
```

</div>



```python
# ë‹¤ì–‘í•œ ìŒì„± ë¹„êµ
sample_text = "Hello! This is a test of different voice styles."

for voice in ["alloy", "nova", "onyx"]:
    print(f"Voice: {voice}")
    audio = text_to_speech(sample_text, voice=voice)
    display(Audio(audio, autoplay=False))
```



<div class="nb-output">

```text
Voice: alloy
<IPython.lib.display.Audio object>
Voice: nova
<IPython.lib.display.Audio object>
Voice: onyx
<IPython.lib.display.Audio object>
```

</div>


---

## 3. ì´ë¯¸ì§€ ë¶„ì„ (Vision)

GPT-4oëŠ” ì´ë¯¸ì§€ë¥¼ ì…ë ¥ë°›ì•„ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ì´ë¯¸ì§€ ì „ë‹¬ ë°©ì‹

1. **URL**: ì›¹ì— ê³µê°œëœ ì´ë¯¸ì§€ URL ì „ë‹¬
2. **Base64**: ë¡œì»¬ ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ ì „ë‹¬

### ë©”ì‹œì§€ êµ¬ì¡°

```python
{
    "role": "user",
    "content": [
        {"type": "text", "text": "ì´ ì´ë¯¸ì§€ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”"},
        {"type": "image_url", "image_url": {"url": "data:image/jpeg;base64,..."}}
    ]
}
```


```python
def encode_image_to_base64(image_path: str) -> str:
    """ì´ë¯¸ì§€ íŒŒì¼ì„ Base64ë¡œ ì¸ì½”ë”©í•©ë‹ˆë‹¤."""
    with open(image_path, "rb") as f:
        return base64.b64encode(f.read()).decode("utf-8")

def analyze_image(image_source: str, prompt: str = "ì´ ì´ë¯¸ì§€ë¥¼ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.") -> str:
    """ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤. URL ë˜ëŠ” íŒŒì¼ ê²½ë¡œë¥¼ ë°›ìŠµë‹ˆë‹¤."""
    
    # URLì¸ì§€ íŒŒì¼ ê²½ë¡œì¸ì§€ íŒë‹¨
    if image_source.startswith(("http://", "https://")):
        image_url = image_source
    else:
        # ë¡œì»¬ íŒŒì¼ â†’ Base64
        base64_image = encode_image_to_base64(image_source)
        # í™•ì¥ìì— ë”°ë¥¸ MIME íƒ€ì… ê²°ì •
        ext = Path(image_source).suffix.lower()
        mime_type = {"jpg": "jpeg", "jpeg": "jpeg", "png": "png", "gif": "gif", "webp": "webp"}.get(ext.strip("."), "jpeg")
        image_url = f"data:image/{mime_type};base64,{base64_image}"
    
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": image_url}}
                ]
            }
        ],
        max_tokens=1000
    )
    
    return response.choices[0].message.content
```



```python
# URL ì´ë¯¸ì§€ ë¶„ì„ í…ŒìŠ¤íŠ¸
image_url = "https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Cat03.jpg/1200px-Cat03.jpg"

description = analyze_image(image_url, "ì´ ì´ë¯¸ì§€ì— ë¬´ì—‡ì´ ìˆë‚˜ìš”? í•œêµ­ì–´ë¡œ ë‹µí•´ì£¼ì„¸ìš”.")
print(description)
```



<div class="nb-output">

```text
ì´ë¯¸ì§€ì—ëŠ” ì£¼í™©ìƒ‰ ì¤„ë¬´ëŠ¬ ê³ ì–‘ì´ê°€ ìˆìŠµë‹ˆë‹¤. ê³ ì–‘ì´ëŠ” ì¹´ë©”ë¼ë¥¼ í–¥í•´ ì •ë©´ì„ ë°”ë¼ë³´ê³  ìˆìŠµë‹ˆë‹¤.
```

</div>



```python
def analyze_pil_image(image: Image.Image, prompt: str = "ì´ ì´ë¯¸ì§€ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.") -> str:
    """PIL Image ê°ì²´ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
    # PIL Image â†’ Base64
    buffer = BytesIO()
    image.save(buffer, format="PNG")
    base64_image = base64.b64encode(buffer.getvalue()).decode("utf-8")
    
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{base64_image}"}}
                ]
            }
        ],
        max_tokens=1000
    )
    
    return response.choices[0].message.content
```



```python
# ìœ„ì—ì„œ ìƒì„±í•œ ì´ë¯¸ì§€ë¥¼ ë‹¤ì‹œ ë¶„ì„í•´ë³´ê¸°
# (ì´ë¯¸ì§€ ìƒì„± ì…€ì„ ë¨¼ì € ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤)
if 'image' in dir():
    analysis = analyze_pil_image(image, "ì´ ì´ë¯¸ì§€ì˜ ë¶„ìœ„ê¸°ì™€ ì£¼ìš” ìš”ì†Œë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.")
    print(analysis)
else:
    print("ë¨¼ì € ì´ë¯¸ì§€ ìƒì„± ì…€ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
```



<div class="nb-output">

```text
ì´ ì´ë¯¸ì§€ëŠ” ë”°ëœ»í•˜ê³  í¸ì•ˆí•œ ë¶„ìœ„ê¸°ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì£¼ìš” ìš”ì†Œë¡œëŠ” ì•„ëŠ‘í•œ ì‹¤ë‚´ ê³µê°„, ë¶€ë“œëŸ¬ìš´ ì¡°ëª…, ë¼íƒ„ ê°€êµ¬, ê·¸ë¦¬ê³  í‰í™”ë¡­ê²Œ ëˆ„ì›Œ ìˆëŠ” ê³ ì–‘ì´ê°€ ìˆìŠµë‹ˆë‹¤. ë‚´ë¶€ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ë‚˜ë¬´ì™€ ì˜¨í™”í•œ ìƒ‰ì¡°ë¡œ ê¾¸ë©°ì ¸ ìˆì–´, í¸ì•ˆí•˜ê³  í¬ê·¼í•œ ëŠë‚Œì„ ì¤ë‹ˆë‹¤. ë˜í•œ, ì„ ë°˜ ìœ„ì˜ ì¥ì‹í’ˆê³¼ ì†ŒíŒŒ, ì¿ ì…˜ë“¤ì´ ì „ë°˜ì ì¸ íœ´ì‹ì˜ ë¶„ìœ„ê¸°ë¥¼ ê°•í™”í•˜ê³  ìˆìŠµë‹ˆë‹¤.
```

</div>


---

## 4. ìŒì„± ì¸ì‹ (Speech-to-Text)

Whisper ëª¨ë¸ë¡œ ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

### API íŒŒë¼ë¯¸í„°

| íŒŒë¼ë¯¸í„° | ì„¤ëª… |
|----------|------|
| `model` | `whisper-1` |
| `file` | ì˜¤ë””ì˜¤ íŒŒì¼ (mp3, wav, m4a ë“±) |
| `language` | ì–¸ì–´ ì½”ë“œ (ì„ íƒ, ì˜ˆ: `ko`, `en`) |


```python
def speech_to_text(audio_path: str, language: str = None) -> str:
    """ìŒì„± íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    with open(audio_path, "rb") as audio_file:
        kwargs = {"model": "whisper-1", "file": audio_file}
        if language:
            kwargs["language"] = language
        
        response = client.audio.transcriptions.create(**kwargs)
    
    return response.text
```



```python
# TTSë¡œ ìƒì„±í•œ ìŒì„±ì„ íŒŒì¼ë¡œ ì €ì¥ í›„ ë‹¤ì‹œ STTë¡œ ë³€í™˜í•˜ëŠ” í…ŒìŠ¤íŠ¸
test_text = "ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì´ ë¹ ë¥´ê²Œ ë°œì „í•˜ê³  ìˆìŠµë‹ˆë‹¤."

# TTSë¡œ ìŒì„± ìƒì„±
audio_bytes = text_to_speech(test_text)

# íŒŒì¼ë¡œ ì €ì¥
audio_path = "test_audio.mp3"
with open(audio_path, "wb") as f:
    f.write(audio_bytes)

print(f"ì›ë³¸ í…ìŠ¤íŠ¸: {test_text}")

# STTë¡œ ë‹¤ì‹œ ë³€í™˜
transcribed = speech_to_text(audio_path, language="ko")
print(f"ë³€í™˜ëœ í…ìŠ¤íŠ¸: {transcribed}")
```



<div class="nb-output">

```text
ì›ë³¸ í…ìŠ¤íŠ¸: ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì´ ë¹ ë¥´ê²Œ ë°œì „í•˜ê³  ìˆìŠµë‹ˆë‹¤.
ë³€í™˜ëœ í…ìŠ¤íŠ¸: ì¸ê³µì§€ëŠ¥ ê¸°ìˆ ì´ ë¹ ë¥´ê²Œ ë°œì „í•˜ê³  ìˆìŠµë‹ˆë‹¤.
```

</div>


---

## 5. í†µí•© ì˜ˆì œ: ì—¬í–‰ ê°€ì´ë“œ ì–´ì‹œìŠ¤í„´íŠ¸

ì§€ê¸ˆê¹Œì§€ ë°°ìš´ ê¸°ëŠ¥ë“¤ì„ ì¡°í•©í•˜ì—¬ ì—¬í–‰ ê°€ì´ë“œ ì–´ì‹œìŠ¤í„´íŠ¸ë¥¼ ë§Œë“¤ì–´ë´…ë‹ˆë‹¤.

- ì—¬í–‰ì§€ ì¶”ì²œ â†’ í…ìŠ¤íŠ¸ ìƒì„±
- ì—¬í–‰ì§€ ì´ë¯¸ì§€ â†’ ì´ë¯¸ì§€ ìƒì„±
- ì„¤ëª… ìŒì„± â†’ TTS


```python
def travel_guide(destination: str):
    """ì—¬í–‰ì§€ì— ëŒ€í•œ ì„¤ëª…, ì´ë¯¸ì§€, ìŒì„±ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    
    print(f"ğŸŒ {destination} ì—¬í–‰ ê°€ì´ë“œ ìƒì„± ì¤‘...\n")
    
    # 1. í…ìŠ¤íŠ¸ ì„¤ëª… ìƒì„±
    print("ğŸ“ ì—¬í–‰ ì •ë³´ ìƒì„± ì¤‘...")
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {
                "role": "system",
                "content": "ë‹¹ì‹ ì€ ì „ë¬¸ ì—¬í–‰ ê°€ì´ë“œì…ë‹ˆë‹¤. ì—¬í–‰ì§€ì— ëŒ€í•´ ê°„ê²°í•˜ê³  ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤."
            },
            {
                "role": "user",
                "content": f"{destination}ì— ëŒ€í•´ 3-4ë¬¸ì¥ìœ¼ë¡œ ì†Œê°œí•´ì£¼ì„¸ìš”. ì¶”ì²œ ëª…ì†Œ 1ê³³ê³¼ ì¶”ì²œ ìŒì‹ 1ê°œë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”."
            }
        ]
    )
    description = response.choices[0].message.content
    print(f"\n{description}\n")
    
    # 2. ì´ë¯¸ì§€ ìƒì„±
    print("ğŸ¨ ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
    image = generate_image(
        f"A beautiful travel photograph of {destination}, "
        f"showing famous landmarks and local atmosphere, "
        f"vibrant colors, professional photography style"
    )
    display(image)
    
    # 3. ìŒì„± ìƒì„±
    print("\nğŸ”Š ìŒì„± ê°€ì´ë“œ ìƒì„± ì¤‘...")
    audio = text_to_speech(description, voice="nova")
    display(Audio(audio, autoplay=True))
    
    return description, image, audio
```



```python
# ì—¬í–‰ ê°€ì´ë“œ ì‹¤í–‰
description, image, audio = travel_guide("seoul, south korea")
```



![output](/images/notebooks/llm-multimodal-basic-img-2.png)



<div class="nb-output">

```text
ğŸŒ seoul, south korea ì—¬í–‰ ê°€ì´ë“œ ìƒì„± ì¤‘...

ğŸ“ ì—¬í–‰ ì •ë³´ ìƒì„± ì¤‘...

ì„œìš¸ì€ í˜„ëŒ€ì™€ ì „í†µì´ ì¡°í™”ë¥¼ ì´ë£¨ëŠ” ë§¤ë ¥ì ì¸ ë„ì‹œë¡œ, ë‹¤ì–‘í•œ ë¬¸í™”ìœ ì‚°ê³¼ í˜„ëŒ€ì ì¸ ì‡¼í•‘ ëª…ì†Œê°€ ê³µì¡´í•©ë‹ˆë‹¤. ì¶”ì²œ ëª…ì†Œë¡œëŠ” ê²½ë³µê¶ì„ ì¶”ì²œí•˜ë©°, ì—¬ê¸°ì„œëŠ” ì „í†µ í•œêµ­ ê±´ì¶•ê³¼ ì•„ë¦„ë‹¤ìš´ ì •ì›ì„ ê°ìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ì„œìš¸ì„ ë°©ë¬¸í•  ë•ŒëŠ” ë°˜ë“œì‹œ ë¹„ë¹”ë°¥ì„ ë§›ë³´ì•„ì•¼ í•©ë‹ˆë‹¤. ì´ í† ì† ìŒì‹ì€ ë‹¤ì–‘í•œ ì±„ì†Œì™€ ê³ ì¶”ì¥ì„ ì„ì–´ ì¦ê¸°ëŠ” ì˜ì–‘ê°€ ë†’ì€ í•œ ê·¸ë¦‡ ìš”ë¦¬ì…ë‹ˆë‹¤.

ğŸ¨ ì´ë¯¸ì§€ ìƒì„± ì¤‘...

ğŸ”Š ìŒì„± ê°€ì´ë“œ ìƒì„± ì¤‘...
<IPython.lib.display.Audio object>
```

</div>


---

## 6. Gradio UIë¡œ ë§Œë“¤ê¸°

Gradioë¥¼ ì‚¬ìš©í•˜ì—¬ ì¸í„°ë™í‹°ë¸Œí•œ Multi-Modal ì•±ì„ ë§Œë“­ë‹ˆë‹¤.


```python
import gradio as gr
```



```python
def travel_guide_ui(destination: str):
    """Gradio UIìš© ì—¬í–‰ ê°€ì´ë“œ í•¨ìˆ˜"""
    if not destination.strip():
        return "ì—¬í–‰ì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.", None, None
    
    # í…ìŠ¤íŠ¸ ì„¤ëª…
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì „ë¬¸ ì—¬í–‰ ê°€ì´ë“œì…ë‹ˆë‹¤."},
            {"role": "user", "content": f"{destination}ì— ëŒ€í•´ 3-4ë¬¸ì¥ìœ¼ë¡œ ì†Œê°œí•´ì£¼ì„¸ìš”."}
        ]
    )
    description = response.choices[0].message.content
    
    # ì´ë¯¸ì§€ ìƒì„±
    image = generate_image(
        f"Beautiful travel photo of {destination}, landmarks, vibrant colors"
    )
    
    # ìŒì„± ìƒì„±
    audio = text_to_speech(description, voice="nova")
    
    return description, image, audio

# Gradio ì•± ìƒì„±
with gr.Blocks(title="ì—¬í–‰ ê°€ì´ë“œ AI") as demo:
    gr.Markdown("# ğŸŒ AI ì—¬í–‰ ê°€ì´ë“œ")
    gr.Markdown("ì—¬í–‰ì§€ë¥¼ ì…ë ¥í•˜ë©´ ì„¤ëª…, ì´ë¯¸ì§€, ìŒì„± ê°€ì´ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
    
    with gr.Row():
        destination_input = gr.Textbox(
            label="ì—¬í–‰ì§€ ì…ë ¥",
            placeholder="ì˜ˆ: íŒŒë¦¬, ë„ì¿„, ì œì£¼ë„..."
        )
        generate_btn = gr.Button("ê°€ì´ë“œ ìƒì„±", variant="primary")
    
    with gr.Row():
        with gr.Column():
            description_output = gr.Textbox(label="ì—¬í–‰ì§€ ì†Œê°œ", lines=5)
            audio_output = gr.Audio(label="ìŒì„± ê°€ì´ë“œ", autoplay=True)
        image_output = gr.Image(label="ì—¬í–‰ì§€ ì´ë¯¸ì§€")
    
    generate_btn.click(
        fn=travel_guide_ui,
        inputs=destination_input,
        outputs=[description_output, image_output, audio_output]
    )

demo.launch()
```



<div class="nb-output">

```text
* Running on local URL:  http://127.0.0.1:7862
* To create a public link, set `share=True` in `launch()`.
<IPython.core.display.HTML object>
```

</div>


---

## ìš”ì•½

ì´ë²ˆ ë…¸íŠ¸ë¶ì—ì„œëŠ” Multi-Modal AIì˜ ê¸°ì´ˆë¥¼ ì•Œì•„ë³´ì•˜ìŠµë‹ˆë‹¤.

### í•µì‹¬ ê¸°ëŠ¥

| ê¸°ëŠ¥ | API | ì£¼ìš” ì‚¬ìš©ì²˜ |
|------|-----|------------|
| ì´ë¯¸ì§€ ìƒì„± | `client.images.generate()` | ì½˜í…ì¸  ìƒì„±, ì‹œê°í™” |
| ìŒì„± ìƒì„± | `client.audio.speech.create()` | ì ‘ê·¼ì„±, ì˜¤ë””ì˜¤ ì½˜í…ì¸  |
| ì´ë¯¸ì§€ ë¶„ì„ | `client.chat.completions.create()` | ì´ë¯¸ì§€ ì´í•´, OCR |
| ìŒì„± ì¸ì‹ | `client.audio.transcriptions.create()` | ìŒì„± ì…ë ¥, íšŒì˜ë¡ |

### ë¹„ìš© ê³ ë ¤ì‚¬í•­

- DALL-E 3: ì´ë¯¸ì§€ë‹¹ ì•½ $0.04
- TTS: 1M ë¬¸ìë‹¹ ì•½ $15
- Whisper: ë¶„ë‹¹ ì•½ $0.006
- Vision: ì´ë¯¸ì§€ í¬ê¸°ì— ë”°ë¼ í† í° ë¹„ìš© ë°œìƒ

### ë‹¤ìŒ ë‹¨ê³„

- Tool Useì™€ ê²°í•©í•˜ì—¬ ë” ë˜‘ë˜‘í•œ ì–´ì‹œìŠ¤í„´íŠ¸ ë§Œë“¤ê¸°
- ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ìŒì„± ëŒ€í™”
- ë¹„ë””ì˜¤ ë¶„ì„ (GPT-4o with video)

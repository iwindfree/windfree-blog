---
title: "Google Colab ì‚¬ìš©í•´ë³´ê¸°: ë¬´ë£Œë¡œ GPU í™˜ê²½ì—ì„œ AI ëª¨ë¸ ì‹¤í–‰í•˜ê¸°"
author: iwindfree
pubDatetime: 2025-01-29T09:00:00Z
slug: "llm-using-google-colab"
category: "LLM Engineering"
series: "LLM Engineering"
seriesOrder: 12
tags: ["ai", "llm", "colab"]
description: "!Open In Colabhttps://colab.research.google.com/assets/colab-badge.svghttps://colab.research.google.com/github/your-repo/google_colab_gpu_guide.ipynb"
---

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/your-repo/google_colab_gpu_guide.ipynb)

## ê°œìš”

**Google Colab**ì€ Googleì´ ì œê³µí•˜ëŠ” ë¬´ë£Œ í´ë¼ìš°ë“œ Jupyter Notebook í™˜ê²½ì…ë‹ˆë‹¤. ë³„ë„ì˜ ì„¤ì¹˜ ì—†ì´ ë¸Œë¼ìš°ì €ì—ì„œ Python ì½”ë“œë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìœ¼ë©°, **ë¬´ë£Œ GPU**ë¥¼ ì œê³µí•©ë‹ˆë‹¤!

## í•™ìŠµ ëª©í‘œ

- âœ… Google Colab GPU ëŸ°íƒ€ì„ ì„¤ì •í•˜ê¸°
- âœ… Colab Secretsìœ¼ë¡œ API í‚¤ ì•ˆì „í•˜ê²Œ ê´€ë¦¬í•˜ê¸°
- âœ… Hugging Face ëª¨ë¸ì„ GPUë¡œ ì‹¤í–‰í•˜ê¸°
- âœ… OpenAI APIë¥¼ Colabì—ì„œ ì‚¬ìš©í•˜ê¸°
- âœ… CPU vs GPU ì„±ëŠ¥ ë¹„êµí•˜ê¸°

## Google Colabì´ë€?

| íŠ¹ì§• | ì„¤ëª… |
|------|------|
| **ë¬´ë£Œ GPU** | NVIDIA Tesla T4 GPU ë¬´ë£Œ ì œê³µ |
| **ì„¤ì¹˜ ë¶ˆí•„ìš”** | ë¸Œë¼ìš°ì €ë§Œ ìˆìœ¼ë©´ ì¦‰ì‹œ ì‹œì‘ |
| **Google Drive ì—°ë™** | íŒŒì¼ ì €ì¥ ë° ê³µìœ  ê°„í¸ |
| **í˜‘ì—…** | ë§í¬ ê³µìœ ë¡œ ì‹¤ì‹œê°„ í˜‘ì—… ê°€ëŠ¥ |
| **ì‚¬ì „ ì„¤ì¹˜ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬** | TensorFlow, PyTorch ë“± ì´ë¯¸ ì„¤ì¹˜ë¨ |

### ë¬´ë£Œ vs Colab Pro ë¹„êµ

| êµ¬ë¶„ | ë¬´ë£Œ | Colab Pro | Colab Pro+ |
|------|------|-----------|------------|
| **ê°€ê²©** | $0 | $9.99/ì›” | $49.99/ì›” |
| **GPU** | T4 (ì œí•œì ) | T4, V100, A100 | V100, A100 (ìš°ì„  í• ë‹¹) |
| **ì„¸ì…˜ ì‹œê°„** | 12ì‹œê°„ | 24ì‹œê°„ | 24ì‹œê°„ |
| **ìœ íœ´ ì‹œê°„** | 90ë¶„ | ë” ê¸´ ìœ íœ´ í—ˆìš© | ë” ê¸´ ìœ íœ´ í—ˆìš© |
| **ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰** | âŒ | âœ… | âœ… |

> ğŸ’¡ **í•™ìŠµ ë° ì‹¤í—˜ ëª©ì **ì´ë¼ë©´ ë¬´ë£Œ ë²„ì „ìœ¼ë¡œë„ ì¶©ë¶„í•©ë‹ˆë‹¤!

---

## 1. GPU ëŸ°íƒ€ì„ ì„¤ì •í•˜ê¸°

Colabì€ ê¸°ë³¸ì ìœ¼ë¡œ CPU ëŸ°íƒ€ì„ìœ¼ë¡œ ì‹œì‘ë©ë‹ˆë‹¤. GPUë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ëŸ°íƒ€ì„ ìœ í˜•ì„ ë³€ê²½í•´ì•¼ í•©ë‹ˆë‹¤.

### ğŸ“Œ GPU í™œì„±í™” ë‹¨ê³„

1. ìƒë‹¨ ë©”ë‰´: **ëŸ°íƒ€ì„(Runtime)** â†’ **ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½(Change runtime type)**
2. **í•˜ë“œì›¨ì–´ ê°€ì†ê¸°(Hardware accelerator)**: **GPU** ì„ íƒ
3. **GPU ìœ í˜•**: T4 (ë¬´ë£Œ ë²„ì „ì€ ìë™ ì„ íƒ)
4. **ì €ì¥(Save)** í´ë¦­

ëŸ°íƒ€ì„ì´ ì¬ì‹œì‘ë˜ë©° GPUê°€ í• ë‹¹ë©ë‹ˆë‹¤.

### GPU í• ë‹¹ í™•ì¸


```python
# GPU ì •ë³´ í™•ì¸ (NVIDIA System Management Interface)
!nvidia-smi
```


**ì¶œë ¥ ì˜ˆì‹œ:**
```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |
| N/A   36C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
```

- **GPU ì´ë¦„**: Tesla T4
- **VRAM**: ì•½ 15GB
- **í˜„ì¬ ì‚¬ìš©ëŸ‰**: 0MiB (ì´ˆê¸° ìƒíƒœ)


```python
# PyTorchë¡œ GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
import torch

if torch.cuda.is_available():
    device = torch.device("cuda")
    print(f"âœ… GPU ì‚¬ìš© ê°€ëŠ¥!")
    print(f"ğŸ“¦ GPU ì´ë¦„: {torch.cuda.get_device_name(0)}")
    print(f"ğŸ’¾ VRAM ì´ëŸ‰: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
else:
    device = torch.device("cpu")
    print("âŒ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëŸ°íƒ€ì„ ìœ í˜•ì„ í™•ì¸í•˜ì„¸ìš”.")
```


---

## 2. Colab Secretsìœ¼ë¡œ API í‚¤ ì•ˆì „í•˜ê²Œ ê´€ë¦¬í•˜ê¸° ğŸ”‘

API í‚¤ë¥¼ ì½”ë“œì— ì§ì ‘ ì…ë ¥í•˜ë©´ **ë³´ì•ˆ ìœ„í—˜**ì´ ìˆìŠµë‹ˆë‹¤. Google Colabì˜ **Secrets** ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë©´ ì•ˆì „í•˜ê²Œ í‚¤ë¥¼ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ğŸ“Œ Colab Secrets ì‚¬ìš© ë°©ë²•

#### 1ë‹¨ê³„: Secrets ì¶”ê°€í•˜ê¸°

1. **ì¢Œì¸¡ ì‚¬ì´ë“œë°”**ì˜ **ì—´ì‡  ì•„ì´ì½˜(ğŸ”‘)** í´ë¦­
2. **+ Add new secret** ë²„íŠ¼ í´ë¦­
3. ë‹¤ìŒ ì •ë³´ ì…ë ¥:

**Hugging Face Token:**
- **Name**: `HF_TOKEN`
- **Value**: `hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx` (ë³¸ì¸ì˜ í† í°)

**OpenAI API Key:**
- **Name**: `OPENAI_API_KEY`
- **Value**: `sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx` (ë³¸ì¸ì˜ í‚¤)

4. **ì €ì¥ í›„ ì¤‘ìš”!** â†’ ê° Secret ì˜†ì˜ **"ë…¸íŠ¸ë¶ ì•¡ì„¸ìŠ¤" í† ê¸€ì„ ì¼œê¸°** âš ï¸

#### 2ë‹¨ê³„: Pythonì—ì„œ Secrets ì‚¬ìš©í•˜ê¸°

```python
from google.colab import userdata

# Secretsì—ì„œ ê°’ ê°€ì ¸ì˜¤ê¸°
hf_token = userdata.get('HF_TOKEN')
openai_key = userdata.get('OPENAI_API_KEY')
```

### ì™œ Secretsì„ ì‚¬ìš©í•´ì•¼ í•˜ë‚˜ìš”?

| ë°©ë²• | ì¥ì  | ë‹¨ì  |
|------|------|------|
| **ì½”ë“œì— ì§ì ‘ ì…ë ¥** | ê°„í¸í•¨ | âŒ ë…¸íŠ¸ë¶ ê³µìœ  ì‹œ í‚¤ ë…¸ì¶œ |
| **í™˜ê²½ ë³€ìˆ˜ (.env)** | ë¡œì»¬ì—ì„œ ì•ˆì „ | âŒ Colabì—ì„œ íŒŒì¼ ì—…ë¡œë“œ í•„ìš” |
| **Colab Secrets** | âœ… ì•ˆì „ + ê°„í¸ | Colab ì „ìš© |

> ğŸ’¡ **SecretsëŠ” ëŸ°íƒ€ì„ì´ ì¬ì‹œì‘ë˜ì–´ë„ ìœ ì§€**ë˜ë©°, ë…¸íŠ¸ë¶ì„ ê³µìœ í•´ë„ í‚¤ëŠ” ë…¸ì¶œë˜ì§€ ì•ŠìŠµë‹ˆë‹¤!


```python
# Secretsì—ì„œ API í‚¤ ë¡œë“œí•˜ê¸°
from google.colab import userdata

# Hugging Face Token ê°€ì ¸ì˜¤ê¸°
try:
    HF_TOKEN = userdata.get('HF_TOKEN')
    print("âœ… HF_TOKEN ë¡œë“œ ì„±ê³µ!")
    print(f"   í† í° ì• 10ì: {HF_TOKEN[:10]}...")
except Exception as e:
    print(f"âŒ HF_TOKENì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Secretsì— ì¶”ê°€í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    print(f"   ì—ëŸ¬: {e}")

# OpenAI API Key ê°€ì ¸ì˜¤ê¸°
try:
    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')
    print("âœ… OPENAI_API_KEY ë¡œë“œ ì„±ê³µ!")
    print(f"   í‚¤ ì• 10ì: {OPENAI_API_KEY[:10]}...")
except Exception as e:
    print(f"âŒ OPENAI_API_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print(f"   ì—ëŸ¬: {e}")
```


---

## 3. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜

Colabì—ëŠ” ë§ì€ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì‚¬ì „ ì„¤ì¹˜ë˜ì–´ ìˆì§€ë§Œ, ìµœì‹  ë²„ì „ì´ í•„ìš”í•˜ê±°ë‚˜ ì¶”ê°€ íŒ¨í‚¤ì§€ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


```python
# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (ì´ë¯¸ ì„¤ì¹˜ëœ ê²½ìš° ì—…ê·¸ë ˆì´ë“œ)
!pip install -q transformers accelerate huggingface_hub openai pillow
```



```python
# ì„¤ì¹˜ëœ ë²„ì „ í™•ì¸
import transformers
import torch
import openai

print(f"PyTorch ë²„ì „: {torch.__version__}")
print(f"CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}")
print(f"Transformers ë²„ì „: {transformers.__version__}")
print(f"OpenAI ë²„ì „: {openai.__version__}")
```


---

## 4. ì‹¤ìŠµ ì˜ˆì œ 1: Hugging Face ëª¨ë¸ GPUë¡œ ì‹¤í–‰í•˜ê¸°

Hugging Faceì˜ í…ìŠ¤íŠ¸ ìƒì„± ëª¨ë¸ì„ GPUì—ì„œ ì‹¤í–‰í•´ë´…ì‹œë‹¤.

### GPT-2ë¡œ í…ìŠ¤íŠ¸ ìƒì„±


```python
from transformers import pipeline
from google.colab import userdata
from huggingface_hub import login

# Hugging Face ë¡œê·¸ì¸ (ì„ íƒì‚¬í•­, ê³µê°œ ëª¨ë¸ì€ ë¶ˆí•„ìš”)
try:
    HF_TOKEN = userdata.get('HF_TOKEN')
    login(token=HF_TOKEN)
    print("âœ… Hugging Face ë¡œê·¸ì¸ ì„±ê³µ!")
except:
    print("âš ï¸ HF_TOKENì´ ì—†ìŠµë‹ˆë‹¤. ê³µê°œ ëª¨ë¸ë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")

# GPUë¥¼ ì‚¬ìš©í•˜ëŠ” í…ìŠ¤íŠ¸ ìƒì„± íŒŒì´í”„ë¼ì¸ ìƒì„±
# device=0: GPU ì‚¬ìš© (CPUëŠ” device=-1)
generator = pipeline(
    "text-generation",
    model="gpt2",
    device=0  # GPU ì‚¬ìš©
)

print("âœ… ëª¨ë¸ì´ GPUì— ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
print(f"   ì‚¬ìš© ì¤‘ì¸ ë””ë°”ì´ìŠ¤: {generator.device}")
```



```python
# í…ìŠ¤íŠ¸ ìƒì„± ì‹¤í–‰
prompt = "Artificial intelligence in healthcare will"

print(f"í”„ë¡¬í”„íŠ¸: {prompt}\n")
print("ìƒì„± ì¤‘...\n")

results = generator(
    prompt,
    max_length=100,
    num_return_sequences=3,
    temperature=0.9,
    do_sample=True
)

for i, result in enumerate(results, 1):
    print(f"=== ìƒì„± ê²°ê³¼ {i} ===")
    print(result['generated_text'])
    print()
```


### CPU vs GPU ì„±ëŠ¥ ë¹„êµ


```python
import time

# CPU íŒŒì´í”„ë¼ì¸
generator_cpu = pipeline("text-generation", model="gpt2", device=-1)

# GPU íŒŒì´í”„ë¼ì¸
generator_gpu = pipeline("text-generation", model="gpt2", device=0)

prompt = "The future of technology is"

# CPU ì„±ëŠ¥ ì¸¡ì •
start_cpu = time.time()
_ = generator_cpu(prompt, max_length=50, num_return_sequences=1)
cpu_time = time.time() - start_cpu

# GPU ì„±ëŠ¥ ì¸¡ì •
start_gpu = time.time()
_ = generator_gpu(prompt, max_length=50, num_return_sequences=1)
gpu_time = time.time() - start_gpu

print("â±ï¸ ì„±ëŠ¥ ë¹„êµ (í…ìŠ¤íŠ¸ ìƒì„±)")
print("=" * 50)
print(f"CPU ì†Œìš” ì‹œê°„: {cpu_time:.3f}ì´ˆ")
print(f"GPU ì†Œìš” ì‹œê°„: {gpu_time:.3f}ì´ˆ")
print(f"ì†ë„ í–¥ìƒ: {cpu_time/gpu_time:.2f}ë°° ë¹ ë¦„")
print("=" * 50)
```


---

## 5. ì‹¤ìŠµ ì˜ˆì œ 2: OpenAI API ì‚¬ìš©í•˜ê¸°

Colabì—ì„œ OpenAI APIë¥¼ ì‚¬ìš©í•´ë´…ì‹œë‹¤. Secretsì— ì €ì¥ëœ API í‚¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.


```python
from openai import OpenAI
from google.colab import userdata

# Secretsì—ì„œ OpenAI API í‚¤ ê°€ì ¸ì˜¤ê¸°
OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')

# OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±
client = OpenAI(api_key=OPENAI_API_KEY)

print("âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ!")
```



```python
# GPT-4o-minië¡œ ëŒ€í™”í•˜ê¸°
response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "system", "content": "You are a helpful AI assistant."},
        {"role": "user", "content": "Explain Google Colab in one sentence."}
    ],
    temperature=0.7,
    max_tokens=100
)

print("ğŸ’¬ AI ì‘ë‹µ:")
print(response.choices[0].message.content)
```


### ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ë°›ê¸°


```python
# ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì‹¤ì‹œê°„ ì‘ë‹µ ë°›ê¸°
print("ğŸ’¬ AI ì‘ë‹µ (ìŠ¤íŠ¸ë¦¬ë°):")

stream = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[
        {"role": "user", "content": "Write a short poem about machine learning."}
    ],
    stream=True
)

for chunk in stream:
    if chunk.choices[0].delta.content is not None:
        print(chunk.choices[0].delta.content, end="")

print()  # ì¤„ë°”ê¿ˆ
```


---

## 6. ì‹¤ìŠµ ì˜ˆì œ 3: ì´ë¯¸ì§€ ë¶„ë¥˜ (Vision Transformer)

GPUë¥¼ í™œìš©í•´ ì´ë¯¸ì§€ ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•´ë´…ì‹œë‹¤.


```python
from transformers import pipeline
from PIL import Image
import requests
from io import BytesIO

# ì´ë¯¸ì§€ ë¶„ë¥˜ íŒŒì´í”„ë¼ì¸ (GPU ì‚¬ìš©)
image_classifier = pipeline("image-classification", device=0)

# ìƒ˜í”Œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
url = "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg"
response = requests.get(url)
image = Image.open(BytesIO(response.content))

# ì´ë¯¸ì§€ í‘œì‹œ
display(image)

# ì´ë¯¸ì§€ ë¶„ë¥˜ ì‹¤í–‰
predictions = image_classifier(image)

print("\nğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ë¥˜ ê²°ê³¼:")
for pred in predictions[:5]:
    print(f"  - {pred['label']}: {pred['score']:.4f}")
```


---

## 7. Google Drive ì—°ë™ (ì„ íƒì‚¬í•­)

ì„¸ì…˜ì´ ì¢…ë£Œë˜ë©´ Colabì˜ ë°ì´í„°ëŠ” ì‚¬ë¼ì§‘ë‹ˆë‹¤. Google Driveë¥¼ ë§ˆìš´íŠ¸í•˜ë©´ íŒŒì¼ì„ ì˜êµ¬ ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


```python
from google.colab import drive

# Google Drive ë§ˆìš´íŠ¸
drive.mount('/content/drive')

print("âœ… Google Driveê°€ /content/driveì— ë§ˆìš´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤!")
print("   íŒŒì¼ì€ /content/drive/MyDrive/ ê²½ë¡œì— ì €ì¥í•˜ì„¸ìš”.")
```



```python
# Driveì— íŒŒì¼ ì €ì¥ ì˜ˆì œ
import os

# ì‘ì—… ë””ë ‰í† ë¦¬ ìƒì„±
save_dir = "/content/drive/MyDrive/colab_projects"
os.makedirs(save_dir, exist_ok=True)

# íŒŒì¼ ì €ì¥
with open(f"{save_dir}/test.txt", "w") as f:
    f.write("Hello from Colab!")

print(f"âœ… íŒŒì¼ì´ {save_dir}/test.txtì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
```


---

## 8. GPU ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§

ëŒ€í˜• ëª¨ë¸ì„ ì‹¤í–‰í•  ë•ŒëŠ” GPU ë©”ëª¨ë¦¬ë¥¼ ëª¨ë‹ˆí„°ë§í•´ì•¼ í•©ë‹ˆë‹¤.


```python
import torch

def print_gpu_memory():
    """í˜„ì¬ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶œë ¥"""
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated(0) / 1e9
        reserved = torch.cuda.memory_reserved(0) / 1e9
        total = torch.cuda.get_device_properties(0).total_memory / 1e9
        
        print("ğŸ“Š GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰")
        print(f"  í• ë‹¹ë¨: {allocated:.2f} GB")
        print(f"  ì˜ˆì•½ë¨: {reserved:.2f} GB")
        print(f"  ì „ì²´: {total:.2f} GB")
        print(f"  ì‚¬ìš©ë¥ : {(reserved/total)*100:.1f}%")
    else:
        print("GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

print_gpu_memory()
```



```python
# GPU ë©”ëª¨ë¦¬ ì •ë¦¬
import gc
import torch

# ë³€ìˆ˜ ì‚­ì œ
# del model, tokenizer  # ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ ì‚­ì œ

# ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
gc.collect()

# PyTorch ìºì‹œ ë¹„ìš°ê¸°
torch.cuda.empty_cache()

print("âœ… GPU ë©”ëª¨ë¦¬ê°€ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤!")
print_gpu_memory()
```


---

## 9. ì£¼ì˜ì‚¬í•­ ë° íŒ ğŸ’¡

### âš ï¸ Colab ì‚¬ìš© ì œí•œì‚¬í•­

| ì œí•œ | ë‚´ìš© |
|------|------|
| **ì„¸ì…˜ ì‹œê°„** | ìµœëŒ€ 12ì‹œê°„ (Pro: 24ì‹œê°„) |
| **ìœ íœ´ ì‹œê°„** | 90ë¶„ ë™ì•ˆ í™œë™ ì—†ìœ¼ë©´ ìë™ ì¢…ë£Œ |
| **GPU í• ë‹¹** | ì‚¬ìš©ëŸ‰ì´ ë§ìœ¼ë©´ GPUë¥¼ í• ë‹¹ë°›ì§€ ëª»í•  ìˆ˜ ìˆìŒ |
| **ë™ì‹œ ì„¸ì…˜** | ë¬´ë£ŒëŠ” 1ê°œ, ProëŠ” ì—¬ëŸ¬ ê°œ ê°€ëŠ¥ |
| **íŒŒì¼ ë³´ì¡´** | ëŸ°íƒ€ì„ ì¢…ë£Œ ì‹œ `/content` ë°ì´í„° ì‚­ì œ |

### ğŸ’¡ ìœ ìš©í•œ íŒ

#### 1. ì„¸ì…˜ ìœ ì§€í•˜ê¸°

```javascript
// ë¸Œë¼ìš°ì € ì½˜ì†”ì—ì„œ ì‹¤í–‰ (F12)
function KeepAlive() {
  console.log("Keeping session alive...");
  document.querySelector("colab-connect-button").click();
}
setInterval(KeepAlive, 60000); // 1ë¶„ë§ˆë‹¤ ì‹¤í–‰
```

âš ï¸ **ì£¼ì˜**: Google ì •ì±… ìœ„ë°˜ ê°€ëŠ¥ì„±ì´ ìˆìœ¼ë¯€ë¡œ ì‹ ì¤‘í•˜ê²Œ ì‚¬ìš©í•˜ì„¸ìš”.

#### 2. GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì—ëŸ¬ í•´ê²°

```python
# ì‘ì€ ë°°ì¹˜ í¬ê¸° ì‚¬ìš©
batch_size = 1  # ê¸°ë³¸ê°’ë³´ë‹¤ ì¤„ì´ê¸°

# Mixed Precision ì‚¬ìš© (FP16)
# torch.cuda.amp í™œìš©

# Gradient Checkpointing
model.gradient_checkpointing_enable()
```

#### 3. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì†ë„ í–¥ìƒ

```python
# ë¯¸ëŸ¬ ì‚¬ì´íŠ¸ ì‚¬ìš©
import os
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
```

#### 4. ëŸ°íƒ€ì„ ì¬ì‹œì‘ í›„ ë¹ ë¥¸ ë³µêµ¬

```python
# ë…¸íŠ¸ë¶ ìƒë‹¨ì— ì´ ì…€ì„ ë°°ì¹˜
# ëŸ°íƒ€ì„ ì¬ì‹œì‘ ì‹œ ì´ ì…€ë§Œ ì‹¤í–‰í•˜ë©´ í™˜ê²½ ë³µêµ¬

!pip install -q transformers accelerate huggingface_hub openai
from google.colab import userdata
HF_TOKEN = userdata.get('HF_TOKEN')
OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')
```

#### 5. í° ëª¨ë¸ ì‚¬ìš© ì‹œ ê¶Œì¥ì‚¬í•­

```python
# 8bit ë˜ëŠ” 4bit ì–‘ìí™” ì‚¬ìš©
from transformers import AutoModelForCausalLM, BitsAndBytesConfig

quantization_config = BitsAndBytesConfig(
    load_in_8bit=True,
    # ë˜ëŠ” load_in_4bit=True
)

model = AutoModelForCausalLM.from_pretrained(
    "model_name",
    quantization_config=quantization_config,
    device_map="auto"
)
```

---

## 10. ê²°ë¡  ë° ìš”ì•½

### ğŸ“ ë°°ìš´ ë‚´ìš©

âœ… Google Colab GPU ëŸ°íƒ€ì„ ì„¤ì •í•˜ê¸°  
âœ… Colab Secretsìœ¼ë¡œ API í‚¤ ì•ˆì „í•˜ê²Œ ê´€ë¦¬í•˜ê¸°  
âœ… Hugging Face ëª¨ë¸ì„ GPUë¡œ ì‹¤í–‰í•˜ê¸°  
âœ… OpenAI APIë¥¼ Colabì—ì„œ ì‚¬ìš©í•˜ê¸°  
âœ… CPU vs GPU ì„±ëŠ¥ ë¹„êµí•˜ê¸°  
âœ… GPU ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ë° ê´€ë¦¬í•˜ê¸°  

### ğŸ”‘ í•µì‹¬ í¬ì¸íŠ¸

1. **Colab Secrets ì‚¬ìš©**
   - ì¢Œì¸¡ ì—´ì‡  ì•„ì´ì½˜(ğŸ”‘) í´ë¦­
   - API í‚¤ë¥¼ ì•ˆì „í•˜ê²Œ ì €ì¥
   - `userdata.get()ìœ¼ë¡œ ì ‘ê·¼`

2. **GPU í™œì„±í™”**
   - ëŸ°íƒ€ì„ â†’ ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½ â†’ GPU ì„ íƒ
   - `device=0` ë˜ëŠ” `device="cuda"`ë¡œ GPU ì‚¬ìš©

3. **ì„¸ì…˜ ê´€ë¦¬**
   - 12ì‹œê°„ ì œí•œ (ë¬´ë£Œ)
   - Google Drive ë§ˆìš´íŠ¸ë¡œ ë°ì´í„° ë³´ì¡´
   - ì¤‘ìš”í•œ íŒŒì¼ì€ Driveì— ì €ì¥

### ğŸ“š ì¶”ê°€ í•™ìŠµ ë¦¬ì†ŒìŠ¤

- [Google Colab ê³µì‹ ë¬¸ì„œ](https://colab.research.google.com/notebooks/)
- [Hugging Face ëª¨ë¸ í—ˆë¸Œ](https://huggingface.co/models)
- [PyTorch GPU íŠœí† ë¦¬ì–¼](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#cuda-tensors)
- [Colab Pro êµ¬ë…](https://colab.research.google.com/signup)



---

**ğŸ‰ ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤!**

ì´ì œ Google Colabì˜ ë¬´ë£Œ GPUë¡œ ë‹¤ì–‘í•œ AI ëª¨ë¸ì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹¤í—˜ì„ ì¦ê¸°ì„¸ìš”!
